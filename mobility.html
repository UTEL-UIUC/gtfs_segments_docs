<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>gtfs_segments.mobility API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>gtfs_segments.mobility</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">import os
import re
from .utils import *
import pandas as pd
import numpy as np

MOBILITY_SOURCES_link = &#34;https://bit.ly/catalogs-csv&#34;
ABBREV_link = &#39;https://raw.githubusercontent.com/UTEL-UIUC/gtfs_segments/main/state_abbreviations.json&#39;

def fetch_gtfs_source(place =&#39;ALL&#39;):
    &#34;&#34;&#34;
    It reads the mobility data sources csv file and generates a dataframe with the sources that are of
    type gtfs and are from the US
    
    Args:
      place: The place you want to get the GTFS data for. This can be a city, state, or country.
    Defaults to ALL
    
    Returns:
      A dataframe with sources
    &#34;&#34;&#34;
    abb_df = pd.read_json(ABBREV_link)
    sources_df = pd.read_csv(MOBILITY_SOURCES_link)
    sources_df = sources_df[sources_df[&#39;location.country_code&#39;] == &#39;US&#39;]
    sources_df = sources_df[sources_df[&#39;data_type&#39;] == &#39;gtfs&#39;]
    sources_df = pd.merge(sources_df,abb_df,how=&#39;left&#39;,left_on=&#39;location.subdivision_name&#39;,right_on=&#39;state&#39;)
    sources_df = sources_df[~sources_df.state_code.isna()]
    sources_df[&#39;location.municipality&#39;] = sources_df[&#39;location.municipality&#39;].astype(&#34;str&#34;)
    sources_df.drop([&#39;entity_type&#39;,&#39;mdb_source_id&#39;,&#39;data_type&#39;,&#39;location.country_code&#39;,&#39;note&#39;,
                     &#39;static_reference&#39;,&#39;urls.direct_download&#39;,&#39;urls.authentication_type&#39;,&#39;urls.license&#39;,&#39;location.bounding_box.extracted_on&#39;, &#39;urls.authentication_info&#39;,&#39;urls.api_key_parameter_name&#39;,&#39;features&#39;],axis=1,inplace=True)
    file_names = []
    for i,row in sources_df.iterrows():
        if row[&#39;location.municipality&#39;] != &#39;nan&#39;:
            if len(sources_df[(sources_df[&#39;location.municipality&#39;] == row[&#39;location.municipality&#39;]) &amp; (sources_df[&#39;provider&#39;] == row[&#39;provider&#39;])]) &lt;= 1:
                f_name = str(row[&#39;location.municipality&#39;])+&#39;-&#39;+str(row[&#39;provider&#39;])+&#39;-&#39;+str(row[&#39;state_code&#39;])
            else:
                f_name = str(row[&#39;location.municipality&#39;])+&#39;-&#39;+str(row[&#39;provider&#39;])+&#39;-&#39;+str(row[&#39;name&#39;])+&#39;-&#39;+str(row[&#39;state_code&#39;])
        else:
            if len(sources_df[(sources_df[&#39;location.subdivision_name&#39;] == row[&#39;location.subdivision_name&#39;]) &amp; (sources_df[&#39;provider&#39;] == row[&#39;provider&#39;])]) &lt;= 1:
                f_name = str(row[&#39;location.subdivision_name&#39;])+&#39;-&#39;+str(row[&#39;provider&#39;])+&#39;-&#39;+str(row[&#39;state_code&#39;])
            else:
                f_name =str(row[&#39;location.subdivision_name&#39;])+&#39;-&#39;+str(row[&#39;provider&#39;])+&#39;-&#39;+str(row[&#39;name&#39;])+&#39;-&#39;+str(row[&#39;state_code&#39;])
        f_name = f_name.replace(&#39;/&#39;,&#39;&#39;).strip()
        file_names.append(f_name)
    sources_df.drop([&#39;provider&#39;,&#39;location.municipality&#39;,&#39;location.subdivision_name&#39;,&#39;name&#39;,&#39;state_code&#39;,&#39;state&#39;],axis=1,inplace=True)
    sources_df.insert(0,&#39;provider&#39;,file_names)
    sources_df.columns = sources_df.columns.str.replace(&#39;location.bounding_box.&#39;,&#34;&#34;,regex=True)
    if place == &#39;ALL&#39;:
        return sources_df
    else:
        sources_df = sources_df[sources_df.apply(lambda row: row.astype(str).str.contains(place.lower(), case=False).any(), axis=1)]
        if len(sources_df) == 0:
            return &#34;No sources found for the given place&#34;
        else:
            return sources_df


def summary_stats_mobility(df,folder_path,filename,b_day,link,bounds,max_spacing = 3000,export = False):
    &#34;&#34;&#34;
    It takes in a dataframe, a folder path, a filename, a busiest day, a link, a bounding box, a max
    spacing, and a boolean for exporting the summary to a csv. 
    
    It then calculates the percentage of segments that have a spacing greater than the max spacing. It
    then filters the dataframe to only include segments with a spacing less than the max spacing. It
    then calculates the segment weighted mean, route weighted mean, traversal weighted mean, traversal
    weighted standard deviation, traversal weighted 25th percentile, traversal weighted 50th percentile,
    traversal weighted 75th percentile, number of segments, number of routes, number of traversals, and
    the max spacing. It then creates a dictionary with all of the above values and creates a dataframe
    from the dictionary. It then exports the dataframe to a csv if the export boolean is true. If the
    export boolean is false, it transposes the dataframe and returns it.
    
    Args:
      df: the dataframe containing the mobility data
      folder_path: The path to the folder where you want to save the summary.csv file.
      filename: The name of the file you want to save the data as.
      b_day: The busiest day of the week
      link: The link of the map you want to use.
      bounds: The bounding box of the area you want to analyze.
      max_spacing: The maximum distance between two stops that you want to consider. Defaults to 3000
      export: If True, the summary will be saved as a csv file in the folder_path. If False, the summary
    will be returned as a dataframe. Defaults to False
    
    Returns:
      A dataframe with the summary statistics of the mobility data.
    &#34;&#34;&#34;
    percent_spacing = round(df[df[&#34;distance&#34;] &gt; max_spacing][&#39;traversals&#39;].sum()/df[&#39;traversals&#39;].sum() *100,3)
    df = df[df[&#34;distance&#34;] &lt;= max_spacing]
    csv_path = os.path.join(folder_path,&#39;summary.csv&#39;)
    stop_weighted_mean = df.groupby([&#39;segment_id&#39;,&#39;distance&#39;]).first().reset_index()[&#34;distance&#34;].mean()
    route_weighted_mean = df.groupby([&#39;route_id&#39;,&#39;segment_id&#39;,&#39;distance&#39;]).first().reset_index()[&#34;distance&#34;].mean()
    weighted_data =  np.hstack([np.repeat(x, y) for x, y in zip(df[&#39;distance&#39;], df.traversals)])
    df_dict = {&#34;Name&#34;:filename,
            &#39;Busiest Day&#39;: b_day,
            &#39;Link&#39;: link,
            &#39;Min Latitude&#39;: bounds[0][1],
            &#39;Min Longitude&#39;: bounds[0][0],
            &#39;Max Latitude&#39;: bounds[1][1],
            &#39;Max Longitude&#39;: bounds[1][0],
            &#39;Segment Weighted Mean&#39; : stop_weighted_mean,
            &#39;Route Weighted Mean&#39; : route_weighted_mean,
            &#39;Traversal Weighted Mean&#39;: round(np.mean(weighted_data),3),
            &#39;Traversal Weighted Std&#39;: round(np.std(weighted_data),3),
            &#39;Traversal Weighted 25 % Quantile&#39;: round(np.quantile(weighted_data,0.25),3),
            &#39;Traversal Weighted 50 % Quantile&#39;: round(np.quantile(weighted_data,0.5),3),
            &#39;Traversal Weighted 75 % Quantile&#39;: round(np.quantile(weighted_data,0.75),3),
            &#39;No of Segments&#39;:len(df),
            &#39;No of Routes&#39;:len(df.route_id.unique()),
            &#39;No of Traversals&#39;:sum(df.traversals),  
            &#39;Max Spacing&#39;:max_spacing,
            &#39;% Segments w/ spacing &gt; max_spacing&#39;:percent_spacing}
    summary_df = pd.DataFrame([df_dict])
    # df.set_index(summary_df.columns[0],inplace=True)
    if export:
        summary_df.to_csv(csv_path,index = False)
        return &#34;Saved the summary.csv in &#34;+folder_path
    else:
       summary_df = summary_df.T
       return summary_df
   
def download_latest_data(out_folder_path,sources_df):
    &#34;&#34;&#34;
    It iterates over the rows of the dataframe, and for each row, it tries to download the file from the
    URL in the `urls.latest` column, and write it to the folder specified in the `provider` column
    
    Args:
      out_folder_path: The path to the folder where you want to save the data
      sources_df: This is the dataframe that contains the urls for the data.
    &#34;&#34;&#34;
    for i,row in sources_df.iterrows():
        try:
            download_write_file(row[&#39;urls.latest&#39;],os.path.join(out_folder_path,row[&#39;provider&#39;]))
        except:
            continue
    print(&#34;Downloaded the latest data&#34;)    
    </code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="gtfs_segments.mobility.download_latest_data"><code class="name flex">
<span>def <span class="ident">download_latest_data</span></span>(<span>out_folder_path, sources_df)</span>
</code></dt>
<dd>
<div class="desc"><p>It iterates over the rows of the dataframe, and for each row, it tries to download the file from the
URL in the <code>urls.latest</code> column, and write it to the folder specified in the <code>provider</code> column</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>out_folder_path</code></strong></dt>
<dd>The path to the folder where you want to save the data</dd>
<dt><strong><code>sources_df</code></strong></dt>
<dd>This is the dataframe that contains the urls for the data.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def download_latest_data(out_folder_path,sources_df):
    &#34;&#34;&#34;
    It iterates over the rows of the dataframe, and for each row, it tries to download the file from the
    URL in the `urls.latest` column, and write it to the folder specified in the `provider` column
    
    Args:
      out_folder_path: The path to the folder where you want to save the data
      sources_df: This is the dataframe that contains the urls for the data.
    &#34;&#34;&#34;
    for i,row in sources_df.iterrows():
        try:
            download_write_file(row[&#39;urls.latest&#39;],os.path.join(out_folder_path,row[&#39;provider&#39;]))
        except:
            continue
    print(&#34;Downloaded the latest data&#34;)    </code></pre>
</details>
</dd>
<dt id="gtfs_segments.mobility.fetch_gtfs_source"><code class="name flex">
<span>def <span class="ident">fetch_gtfs_source</span></span>(<span>place='ALL')</span>
</code></dt>
<dd>
<div class="desc"><p>It reads the mobility data sources csv file and generates a dataframe with the sources that are of
type gtfs and are from the US</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>place</code></strong></dt>
<dd>The place you want to get the GTFS data for. This can be a city, state, or country.</dd>
</dl>
<p>Defaults to ALL</p>
<h2 id="returns">Returns</h2>
<p>A dataframe with sources</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def fetch_gtfs_source(place =&#39;ALL&#39;):
    &#34;&#34;&#34;
    It reads the mobility data sources csv file and generates a dataframe with the sources that are of
    type gtfs and are from the US
    
    Args:
      place: The place you want to get the GTFS data for. This can be a city, state, or country.
    Defaults to ALL
    
    Returns:
      A dataframe with sources
    &#34;&#34;&#34;
    abb_df = pd.read_json(ABBREV_link)
    sources_df = pd.read_csv(MOBILITY_SOURCES_link)
    sources_df = sources_df[sources_df[&#39;location.country_code&#39;] == &#39;US&#39;]
    sources_df = sources_df[sources_df[&#39;data_type&#39;] == &#39;gtfs&#39;]
    sources_df = pd.merge(sources_df,abb_df,how=&#39;left&#39;,left_on=&#39;location.subdivision_name&#39;,right_on=&#39;state&#39;)
    sources_df = sources_df[~sources_df.state_code.isna()]
    sources_df[&#39;location.municipality&#39;] = sources_df[&#39;location.municipality&#39;].astype(&#34;str&#34;)
    sources_df.drop([&#39;entity_type&#39;,&#39;mdb_source_id&#39;,&#39;data_type&#39;,&#39;location.country_code&#39;,&#39;note&#39;,
                     &#39;static_reference&#39;,&#39;urls.direct_download&#39;,&#39;urls.authentication_type&#39;,&#39;urls.license&#39;,&#39;location.bounding_box.extracted_on&#39;, &#39;urls.authentication_info&#39;,&#39;urls.api_key_parameter_name&#39;,&#39;features&#39;],axis=1,inplace=True)
    file_names = []
    for i,row in sources_df.iterrows():
        if row[&#39;location.municipality&#39;] != &#39;nan&#39;:
            if len(sources_df[(sources_df[&#39;location.municipality&#39;] == row[&#39;location.municipality&#39;]) &amp; (sources_df[&#39;provider&#39;] == row[&#39;provider&#39;])]) &lt;= 1:
                f_name = str(row[&#39;location.municipality&#39;])+&#39;-&#39;+str(row[&#39;provider&#39;])+&#39;-&#39;+str(row[&#39;state_code&#39;])
            else:
                f_name = str(row[&#39;location.municipality&#39;])+&#39;-&#39;+str(row[&#39;provider&#39;])+&#39;-&#39;+str(row[&#39;name&#39;])+&#39;-&#39;+str(row[&#39;state_code&#39;])
        else:
            if len(sources_df[(sources_df[&#39;location.subdivision_name&#39;] == row[&#39;location.subdivision_name&#39;]) &amp; (sources_df[&#39;provider&#39;] == row[&#39;provider&#39;])]) &lt;= 1:
                f_name = str(row[&#39;location.subdivision_name&#39;])+&#39;-&#39;+str(row[&#39;provider&#39;])+&#39;-&#39;+str(row[&#39;state_code&#39;])
            else:
                f_name =str(row[&#39;location.subdivision_name&#39;])+&#39;-&#39;+str(row[&#39;provider&#39;])+&#39;-&#39;+str(row[&#39;name&#39;])+&#39;-&#39;+str(row[&#39;state_code&#39;])
        f_name = f_name.replace(&#39;/&#39;,&#39;&#39;).strip()
        file_names.append(f_name)
    sources_df.drop([&#39;provider&#39;,&#39;location.municipality&#39;,&#39;location.subdivision_name&#39;,&#39;name&#39;,&#39;state_code&#39;,&#39;state&#39;],axis=1,inplace=True)
    sources_df.insert(0,&#39;provider&#39;,file_names)
    sources_df.columns = sources_df.columns.str.replace(&#39;location.bounding_box.&#39;,&#34;&#34;,regex=True)
    if place == &#39;ALL&#39;:
        return sources_df
    else:
        sources_df = sources_df[sources_df.apply(lambda row: row.astype(str).str.contains(place.lower(), case=False).any(), axis=1)]
        if len(sources_df) == 0:
            return &#34;No sources found for the given place&#34;
        else:
            return sources_df</code></pre>
</details>
</dd>
<dt id="gtfs_segments.mobility.summary_stats_mobility"><code class="name flex">
<span>def <span class="ident">summary_stats_mobility</span></span>(<span>df, folder_path, filename, b_day, link, bounds, max_spacing=3000, export=False)</span>
</code></dt>
<dd>
<div class="desc"><p>It takes in a dataframe, a folder path, a filename, a busiest day, a link, a bounding box, a max
spacing, and a boolean for exporting the summary to a csv. </p>
<p>It then calculates the percentage of segments that have a spacing greater than the max spacing. It
then filters the dataframe to only include segments with a spacing less than the max spacing. It
then calculates the segment weighted mean, route weighted mean, traversal weighted mean, traversal
weighted standard deviation, traversal weighted 25th percentile, traversal weighted 50th percentile,
traversal weighted 75th percentile, number of segments, number of routes, number of traversals, and
the max spacing. It then creates a dictionary with all of the above values and creates a dataframe
from the dictionary. It then exports the dataframe to a csv if the export boolean is true. If the
export boolean is false, it transposes the dataframe and returns it.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>df</code></strong></dt>
<dd>the dataframe containing the mobility data</dd>
<dt><strong><code>folder_path</code></strong></dt>
<dd>The path to the folder where you want to save the summary.csv file.</dd>
<dt><strong><code>filename</code></strong></dt>
<dd>The name of the file you want to save the data as.</dd>
<dt><strong><code>b_day</code></strong></dt>
<dd>The busiest day of the week</dd>
<dt><strong><code>link</code></strong></dt>
<dd>The link of the map you want to use.</dd>
<dt><strong><code>bounds</code></strong></dt>
<dd>The bounding box of the area you want to analyze.</dd>
<dt><strong><code>max_spacing</code></strong></dt>
<dd>The maximum distance between two stops that you want to consider. Defaults to 3000</dd>
<dt><strong><code>export</code></strong></dt>
<dd>If True, the summary will be saved as a csv file in the folder_path. If False, the summary</dd>
</dl>
<p>will be returned as a dataframe. Defaults to False</p>
<h2 id="returns">Returns</h2>
<p>A dataframe with the summary statistics of the mobility data.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def summary_stats_mobility(df,folder_path,filename,b_day,link,bounds,max_spacing = 3000,export = False):
    &#34;&#34;&#34;
    It takes in a dataframe, a folder path, a filename, a busiest day, a link, a bounding box, a max
    spacing, and a boolean for exporting the summary to a csv. 
    
    It then calculates the percentage of segments that have a spacing greater than the max spacing. It
    then filters the dataframe to only include segments with a spacing less than the max spacing. It
    then calculates the segment weighted mean, route weighted mean, traversal weighted mean, traversal
    weighted standard deviation, traversal weighted 25th percentile, traversal weighted 50th percentile,
    traversal weighted 75th percentile, number of segments, number of routes, number of traversals, and
    the max spacing. It then creates a dictionary with all of the above values and creates a dataframe
    from the dictionary. It then exports the dataframe to a csv if the export boolean is true. If the
    export boolean is false, it transposes the dataframe and returns it.
    
    Args:
      df: the dataframe containing the mobility data
      folder_path: The path to the folder where you want to save the summary.csv file.
      filename: The name of the file you want to save the data as.
      b_day: The busiest day of the week
      link: The link of the map you want to use.
      bounds: The bounding box of the area you want to analyze.
      max_spacing: The maximum distance between two stops that you want to consider. Defaults to 3000
      export: If True, the summary will be saved as a csv file in the folder_path. If False, the summary
    will be returned as a dataframe. Defaults to False
    
    Returns:
      A dataframe with the summary statistics of the mobility data.
    &#34;&#34;&#34;
    percent_spacing = round(df[df[&#34;distance&#34;] &gt; max_spacing][&#39;traversals&#39;].sum()/df[&#39;traversals&#39;].sum() *100,3)
    df = df[df[&#34;distance&#34;] &lt;= max_spacing]
    csv_path = os.path.join(folder_path,&#39;summary.csv&#39;)
    stop_weighted_mean = df.groupby([&#39;segment_id&#39;,&#39;distance&#39;]).first().reset_index()[&#34;distance&#34;].mean()
    route_weighted_mean = df.groupby([&#39;route_id&#39;,&#39;segment_id&#39;,&#39;distance&#39;]).first().reset_index()[&#34;distance&#34;].mean()
    weighted_data =  np.hstack([np.repeat(x, y) for x, y in zip(df[&#39;distance&#39;], df.traversals)])
    df_dict = {&#34;Name&#34;:filename,
            &#39;Busiest Day&#39;: b_day,
            &#39;Link&#39;: link,
            &#39;Min Latitude&#39;: bounds[0][1],
            &#39;Min Longitude&#39;: bounds[0][0],
            &#39;Max Latitude&#39;: bounds[1][1],
            &#39;Max Longitude&#39;: bounds[1][0],
            &#39;Segment Weighted Mean&#39; : stop_weighted_mean,
            &#39;Route Weighted Mean&#39; : route_weighted_mean,
            &#39;Traversal Weighted Mean&#39;: round(np.mean(weighted_data),3),
            &#39;Traversal Weighted Std&#39;: round(np.std(weighted_data),3),
            &#39;Traversal Weighted 25 % Quantile&#39;: round(np.quantile(weighted_data,0.25),3),
            &#39;Traversal Weighted 50 % Quantile&#39;: round(np.quantile(weighted_data,0.5),3),
            &#39;Traversal Weighted 75 % Quantile&#39;: round(np.quantile(weighted_data,0.75),3),
            &#39;No of Segments&#39;:len(df),
            &#39;No of Routes&#39;:len(df.route_id.unique()),
            &#39;No of Traversals&#39;:sum(df.traversals),  
            &#39;Max Spacing&#39;:max_spacing,
            &#39;% Segments w/ spacing &gt; max_spacing&#39;:percent_spacing}
    summary_df = pd.DataFrame([df_dict])
    # df.set_index(summary_df.columns[0],inplace=True)
    if export:
        summary_df.to_csv(csv_path,index = False)
        return &#34;Saved the summary.csv in &#34;+folder_path
    else:
       summary_df = summary_df.T
       return summary_df</code></pre>
</details>
</dd>
</dl>
</section>
<section>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="gtfs_segments" href="index.html">gtfs_segments</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="gtfs_segments.mobility.download_latest_data" href="#gtfs_segments.mobility.download_latest_data">download_latest_data</a></code></li>
<li><code><a title="gtfs_segments.mobility.fetch_gtfs_source" href="#gtfs_segments.mobility.fetch_gtfs_source">fetch_gtfs_source</a></code></li>
<li><code><a title="gtfs_segments.mobility.summary_stats_mobility" href="#gtfs_segments.mobility.summary_stats_mobility">summary_stats_mobility</a></code></li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>